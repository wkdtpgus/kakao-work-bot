"""
QA Agentìš© ë„êµ¬ë“¤
"""

from typing import Optional
from langchain.tools import BaseTool
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import os
from ..utils.models import CHAT_MODEL_CONFIG


# =============================================================================
# Tool Input Schemas
# =============================================================================

class QualityQuestionInput(BaseModel):
    """ì–‘ì§ˆì˜ ì§ˆë¬¸ ìƒì„± íˆ´ ì…ë ¥"""
    user_context: str = Field(description="ì‚¬ìš©ìì˜ ì§ë¬´, ëª©í‘œ, ìµœê·¼ ì—…ë¬´ ë“± ì»¨í…ìŠ¤íŠ¸")
    topic: Optional[str] = Field(default=None, description="ì§ˆë¬¸ ì£¼ì œ (ì˜ˆ: ì»¤ë¦¬ì–´, í”„ë¡œì íŠ¸, ì„±ê³¼)")


class WeeklyFeedbackInput(BaseModel):
    """ì£¼ê°„ í”¼ë“œë°± ìƒì„± íˆ´ ì…ë ¥"""
    weekly_records: str = Field(description="ì£¼ê°„ ê¸°ë¡ ë‚´ìš© (JSON ë˜ëŠ” í…ìŠ¤íŠ¸)")
    user_metadata: str = Field(description="ì‚¬ìš©ì ë©”íƒ€ë°ì´í„° (ì´ë¦„, ì§ë¬´, ëª©í‘œ ë“±)")


class TemplateInput(BaseModel):
    """í…œí”Œë¦¿ ìƒì„± íˆ´ ì…ë ¥"""
    template_type: str = Field(description="í…œí”Œë¦¿ ì¢…ë¥˜ (ì˜ˆ: ì¼ì¼ê¸°ë¡, íšŒê³ , ì´ë ¥ì„œ)")
    user_context: str = Field(description="ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸")


# =============================================================================
# Tools
# =============================================================================

class QualityQuestionTool(BaseTool):
    """ì–‘ì§ˆì˜ ì§ˆë¬¸ ìƒì„± ë„êµ¬

    ì‚¬ìš©ìì˜ ì¼ì¼ ê¸°ë¡ì„ ë•ê¸° ìœ„í•´ ë§¥ë½ì— ë§ëŠ” ê¹Šì´ ìˆëŠ” ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """

    name: str = "quality_question_generator"
    description: str = """ì‚¬ìš©ìì˜ ì§ë¬´ì™€ ëª©í‘œì— ë§ëŠ” ì–‘ì§ˆì˜ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì´ ë„êµ¬ëŠ” ì‚¬ìš©ìê°€ ìì‹ ì˜ ì—…ë¬´ë¥¼ ë” ê¹Šì´ ì„±ì°°í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.
    ì…ë ¥: user_context (ì‚¬ìš©ì ì •ë³´), topic (ì„ íƒ ì£¼ì œ)
    ì¶œë ¥: 3-5ê°œì˜ ì„±ì°° ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸"""
    args_schema: type[BaseModel] = QualityQuestionInput

    def _run(self, user_context: str, topic: Optional[str] = None) -> str:
        """ì§ˆë¬¸ ìƒì„± ì‹¤í–‰"""
        llm = ChatOpenAI(**CHAT_MODEL_CONFIG, api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸:
{user_context}

ì£¼ì œ: {topic or 'ì¼ì¼ ì—…ë¬´ ê¸°ë¡'}

ìœ„ ì‚¬ìš©ìì˜ ì§ë¬´ì™€ ëª©í‘œì— ë§ëŠ” ê¹Šì´ ìˆëŠ” ì„±ì°° ì§ˆë¬¸ 3-5ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ì§ˆë¬¸ì€ ì‚¬ìš©ìê°€ ìì‹ ì˜ ì—…ë¬´ ê²½í—˜ì„ ë” ê¹Šì´ íƒêµ¬í•˜ê³ , ë°°ì›€ê³¼ ì„±ì¥ì„ ë°œê²¬í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì•¼ í•©ë‹ˆë‹¤.

ì¶œë ¥ í˜•ì‹:
1. [ì§ˆë¬¸]
2. [ì§ˆë¬¸]
..."""

        response = llm.invoke([
            SystemMessage(content="ë‹¹ì‹ ì€ ì»¤ë¦¬ì–´ ì½”ì¹­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì„±ì¥ì„ ë•ëŠ” í†µì°°ë ¥ ìˆëŠ” ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."),
            HumanMessage(content=prompt)
        ])

        return response.content

    async def _arun(self, user_context: str, topic: Optional[str] = None) -> str:
        """ë¹„ë™ê¸° ì‹¤í–‰"""
        llm = ChatOpenAI(**CHAT_MODEL_CONFIG, api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸:
{user_context}

ì£¼ì œ: {topic or 'ì¼ì¼ ì—…ë¬´ ê¸°ë¡'}

ìœ„ ì‚¬ìš©ìì˜ ì§ë¬´ì™€ ëª©í‘œì— ë§ëŠ” ê¹Šì´ ìˆëŠ” ì„±ì°° ì§ˆë¬¸ 3-5ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ì§ˆë¬¸ì€ ì‚¬ìš©ìê°€ ìì‹ ì˜ ì—…ë¬´ ê²½í—˜ì„ ë” ê¹Šì´ íƒêµ¬í•˜ê³ , ë°°ì›€ê³¼ ì„±ì¥ì„ ë°œê²¬í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì•¼ í•©ë‹ˆë‹¤.

ì¶œë ¥ í˜•ì‹:
1. [ì§ˆë¬¸]
2. [ì§ˆë¬¸]
..."""

        response = await llm.ainvoke([
            SystemMessage(content="ë‹¹ì‹ ì€ ì»¤ë¦¬ì–´ ì½”ì¹­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì„±ì¥ì„ ë•ëŠ” í†µì°°ë ¥ ìˆëŠ” ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."),
            HumanMessage(content=prompt)
        ])

        return response.content


class WeeklyFeedbackTool(BaseTool):
    """ì£¼ê°„ í”¼ë“œë°± ìƒì„± ë„êµ¬

    ì¼ì£¼ì¼ ê°„ì˜ ì¼ì¼ ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ì™€ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.
    """

    name: str = "weekly_feedback_generator"
    description: str = """ì£¼ê°„ ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤.
    íŒ¨í„´ ì¸ì‹, ì„±ê³¼ í•˜ì´ë¼ì´íŠ¸, ê°œì„  ì œì•ˆ ë“±ì„ í¬í•¨í•©ë‹ˆë‹¤.
    ì…ë ¥: weekly_records (ì£¼ê°„ ê¸°ë¡), user_metadata (ì‚¬ìš©ì ì •ë³´)
    ì¶œë ¥: êµ¬ì¡°í™”ëœ ì£¼ê°„ í”¼ë“œë°± ë¦¬í¬íŠ¸"""
    args_schema: type[BaseModel] = WeeklyFeedbackInput

    def _run(self, weekly_records: str, user_metadata: str) -> str:
        """í”¼ë“œë°± ìƒì„± ì‹¤í–‰"""
        llm = ChatOpenAI(**CHAT_MODEL_CONFIG, api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""ì‚¬ìš©ì ì •ë³´:
{user_metadata}

ì£¼ê°„ ê¸°ë¡:
{weekly_records}

ìœ„ ì£¼ê°„ ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•œ í”¼ë“œë°±ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
1. ì´ë²ˆ ì£¼ í•˜ì´ë¼ì´íŠ¸ (ì£¼ìš” ì„±ê³¼ 3ê°€ì§€)
2. ë°œê²¬ëœ íŒ¨í„´ (ì—…ë¬´ íŒ¨í„´, ì„±ì¥ í¬ì¸íŠ¸)
3. ë‹¤ìŒ ì£¼ ì œì•ˆ (ê°œì„  ë°©í–¥, ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸)

ì¶œë ¥ì€ ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        response = llm.invoke([
            SystemMessage(content="ë‹¹ì‹ ì€ ê²½ë ¥ ê°œë°œ ì½”ì¹˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì£¼ê°„ ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ í†µì°°ë ¥ ìˆëŠ” í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."),
            HumanMessage(content=prompt)
        ])

        return response.content

    async def _arun(self, weekly_records: str, user_metadata: str) -> str:
        """ë¹„ë™ê¸° ì‹¤í–‰"""
        llm = ChatOpenAI(**CHAT_MODEL_CONFIG, api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""ì‚¬ìš©ì ì •ë³´:
{user_metadata}

ì£¼ê°„ ê¸°ë¡:
{weekly_records}

ìœ„ ì£¼ê°„ ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•œ í”¼ë“œë°±ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
1. ì´ë²ˆ ì£¼ í•˜ì´ë¼ì´íŠ¸ (ì£¼ìš” ì„±ê³¼ 3ê°€ì§€)
2. ë°œê²¬ëœ íŒ¨í„´ (ì—…ë¬´ íŒ¨í„´, ì„±ì¥ í¬ì¸íŠ¸)
3. ë‹¤ìŒ ì£¼ ì œì•ˆ (ê°œì„  ë°©í–¥, ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸)

ì¶œë ¥ì€ ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        response = await llm.ainvoke([
            SystemMessage(content="ë‹¹ì‹ ì€ ê²½ë ¥ ê°œë°œ ì½”ì¹˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì£¼ê°„ ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ í†µì°°ë ¥ ìˆëŠ” í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."),
            HumanMessage(content=prompt)
        ])

        return response.content


class TemplateTool(BaseTool):
    """í…œí”Œë¦¿ ìƒì„± ë„êµ¬

    ì¼ì¼ ê¸°ë¡, íšŒê³ , ì´ë ¥ì„œ ë“± ë‹¤ì–‘í•œ í…œí”Œë¦¿ì„ ì‚¬ìš©ìì— ë§ê²Œ ìƒì„±í•©ë‹ˆë‹¤.
    """

    name: str = "template_generator"
    description: str = """ì‚¬ìš©ì ë§ì¶¤í˜• í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì¼ì¼ ê¸°ë¡, íšŒê³ , ì´ë ¥ì„œ ë“±ì˜ í…œí”Œë¦¿ì„ ì œê³µí•©ë‹ˆë‹¤.
    ì…ë ¥: template_type (í…œí”Œë¦¿ ì¢…ë¥˜), user_context (ì‚¬ìš©ì ì •ë³´)
    ì¶œë ¥: ë§ì¶¤í˜• í…œí”Œë¦¿ í…ìŠ¤íŠ¸"""
    args_schema: type[BaseModel] = TemplateInput

    def _run(self, template_type: str, user_context: str) -> str:
        """í…œí”Œë¦¿ ìƒì„± ì‹¤í–‰"""
        # TODO: LLMì„ ì‚¬ìš©í•œ ì‹¤ì œ í…œí”Œë¦¿ ìƒì„± ë¡œì§

        templates = {
            "ì¼ì¼ê¸°ë¡": """
ğŸ“ ì¼ì¼ ê¸°ë¡ í…œí”Œë¦¿

ë‚ ì§œ: [YYYY-MM-DD]

ì˜¤ëŠ˜ì˜ ì£¼ìš” ì—…ë¬´:
â€¢

ì–´ë ¤ì› ë˜ ì  / ë„ì „:
â€¢

ë°°ìš´ ì  / ì¸ì‚¬ì´íŠ¸:
â€¢

ë‚´ì¼ ê³„íš:
â€¢
""",
            "íšŒê³ ": """
ğŸ” íšŒê³  í…œí”Œë¦¿

ê¸°ê°„: [ì‹œì‘ì¼ ~ ì¢…ë£Œì¼]

ì˜í•œ ì  (Keep):
â€¢

ê°œì„ í•  ì  (Problem):
â€¢

ì‹œë„í•´ë³¼ ì  (Try):
â€¢
""",
            "ì´ë ¥ì„œ": """
ğŸ“„ ê²½ë ¥ ê¸°ìˆ ì„œ í…œí”Œë¦¿

[í”„ë¡œì íŠ¸ëª…]
â€¢ ê¸°ê°„:
â€¢ ì—­í• :
â€¢ ì‚¬ìš© ê¸°ìˆ :
â€¢ ì£¼ìš” ì„±ê³¼:
â€¢ ë°°ìš´ ì :
"""
        }

        return templates.get(template_type, "í•´ë‹¹ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.").strip()

    async def _arun(self, template_type: str, user_context: str) -> str:
        """ë¹„ë™ê¸° ì‹¤í–‰"""
        return self._run(template_type, user_context)


# =============================================================================
# Tool List
# =============================================================================

def get_qa_tools():
    """QA Agentì—ì„œ ì‚¬ìš©í•  ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    return [
        QualityQuestionTool(),
        WeeklyFeedbackTool(),
        TemplateTool()
    ]
