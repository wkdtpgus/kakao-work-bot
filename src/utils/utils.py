import re
import random
import os
from typing import List, Dict, Any, Optional, Type, Tuple
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

# ì£¼ì˜: get_system_prompt, format_user_prompt í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
# ìƒˆë¡œìš´ ì˜¨ë³´ë”© ë°©ì‹ì€ nodes.pyì—ì„œ ì§ì ‘ EXTRACTION_SYSTEM_PROMPTë¥¼ ì‚¬ìš©í•¨

def simple_text_response(text: str) -> Dict[str, Any]:
    """ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì‘ë‹µ (ì¹´ì¹´ì˜¤í†¡ API í¬ë§·)"""
    return {
        "version": "2.0",
        "template": {
            "outputs": [{
                "simpleText": {
                    "text": text
                }
            }]
        }
    }




# =============================================================================
# ì˜¨ë³´ë”© ê´€ë ¨ í—¬í¼ í•¨ìˆ˜ë“¤
# =============================================================================

def is_onboarding_complete(current_state: Dict[str, Any]) -> bool:
    """ì˜¨ë³´ë”© ì™„ë£Œ ì—¬ë¶€ ì²´í¬"""
    required_fields = [
        "name", "job_title", "total_years", "job_years",
        "career_goal", "project_name", "recent_work", "job_meaning", "important_thing"
    ]

    return all(current_state.get(field) is not None for field in required_fields)


# =============================================================================
# Nodes.pyì—ì„œ ì¶”ì¶œí•œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í—¬í¼ í•¨ìˆ˜ë“¤
# =============================================================================

# -----------------------------------------------------------------------------
# 1. ëŒ€í™” íˆìŠ¤í† ë¦¬ ì²˜ë¦¬ ê´€ë ¨
# -----------------------------------------------------------------------------

def extract_last_bot_message(cached_today_turns: List[Dict[str, str]]) -> Optional[str]:
    """
    ìµœê·¼ ëŒ€í™” í„´ì—ì„œ ë§ˆì§€ë§‰ ë´‡ ë©”ì‹œì§€ë¥¼ ì¶”ì¶œ

    Args:
        cached_today_turns: [{"user_message": "...", "ai_message": "..."}, ...] í˜•ì‹

    Returns:
        ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ë˜ëŠ” None

    Usage:
        service_router_node, daily_agent_nodeì—ì„œ ë§¥ë½ íŒŒì•…ìš©
    """
    if not cached_today_turns:
        return None

    last_turn = cached_today_turns[-1]
    return last_turn.get("ai_message")


def enhance_message_with_context(message: str, last_bot_message: Optional[str]) -> str:
    """
    ì‚¬ìš©ì ë©”ì‹œì§€ì— ì§ì „ ë´‡ ë©”ì‹œì§€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€

    Args:
        message: í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€
        last_bot_message: ì§ì „ ë´‡ ë©”ì‹œì§€ (ì—†ìœ¼ë©´ None)

    Returns:
        ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ê°•í™” ë©”ì‹œì§€

    Usage:
        ì˜ë„ ë¶„ë¥˜ ì‹œ ì§ì „ ëŒ€í™” ë§¥ë½ì„ LLMì— ì „ë‹¬
    """
    if last_bot_message:
        return f"[Previous bot]: {last_bot_message}\n[User]: {message}"
    return message


def format_conversation_history(
    messages: List[Dict[str, str]],
    max_turns: int = 3,
    role_key: str = "role",
    content_key: str = "content"
) -> str:
    """
    ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…

    Args:
        messages: [{"role": "assistant"|"user", "content": "..."}, ...] í˜•ì‹
        max_turns: ìµœê·¼ Ní„´ë§Œ í¬í•¨ (ê¸°ë³¸ 3í„´)
        role_key: role í‚¤ ì´ë¦„
        content_key: content í‚¤ ì´ë¦„

    Returns:
        í¬ë§·íŒ…ëœ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¬¸ìì—´

    Usage:
        ì˜¨ë³´ë”© LLM í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
    """
    if not messages:
        return "(ì²« ë©”ì‹œì§€)"

    recent_messages = messages[-max_turns * 2:] if len(messages) > max_turns * 2 else messages

    history_lines = []
    for msg in recent_messages:
        role = "ë´‡" if msg.get(role_key) == "assistant" else "ì‚¬ìš©ì"
        content = msg.get(content_key, "")
        history_lines.append(f"{role}: {content}")

    return "\n".join(history_lines) if history_lines else "(ì²« ë©”ì‹œì§€)"


# -----------------------------------------------------------------------------
# 2. LLM í˜¸ì¶œ ë° ì‘ë‹µ ì²˜ë¦¬
# -----------------------------------------------------------------------------

async def safe_llm_invoke(
    llm,
    system_prompt: str,
    user_prompt: str,
    fallback_message: str = "ì£„ì†¡í•©ë‹ˆë‹¤. ì ì‹œ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
) -> str:
    """
    LLM í˜¸ì¶œ + None ì²´í¬ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬

    Args:
        llm: LangChain LLM ì¸ìŠ¤í„´ìŠ¤
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        user_prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        fallback_message: LLMì´ None ë°˜í™˜ ì‹œ í´ë°± ë©”ì‹œì§€

    Returns:
        LLM ì‘ë‹µ í…ìŠ¤íŠ¸ ë˜ëŠ” í´ë°± ë©”ì‹œì§€

    Usage:
        service_router_node, daily_agent_nodeì—ì„œ ì•ˆì „í•œ LLM í˜¸ì¶œ
    """
    from langchain_core.messages import SystemMessage, HumanMessage

    try:
        response = await llm.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])

        if response is None or not response.content:
            logger.warning("[safe_llm_invoke] LLMì´ None ë°˜í™˜")
            return fallback_message

        return response.content.strip()

    except Exception as e:
        logger.error(f"[safe_llm_invoke] LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return fallback_message


async def invoke_structured_llm(
    llm,
    schema_class: Type,
    system_prompt: str,
    user_prompt: str,
    fallback_value: Any = None
):
    """
    Structured Output LLM í˜¸ì¶œ + ì—ëŸ¬ í•¸ë“¤ë§

    Args:
        llm: LangChain LLM ì¸ìŠ¤í„´ìŠ¤ (ì›ë³¸)
        schema_class: Pydantic ìŠ¤í‚¤ë§ˆ í´ë˜ìŠ¤ (ExtractionResponse ë“±)
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        user_prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        fallback_value: LLM ì‹¤íŒ¨ ì‹œ ë°˜í™˜í•  ê¸°ë³¸ê°’

    Returns:
        schema_class ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” fallback_value

    Usage:
        ì˜¨ë³´ë”© ì˜ë„ ì¶”ì¶œ ë“± structured output í•„ìš” ì‹œ
    """
    from langchain_core.messages import SystemMessage, HumanMessage

    try:
        structured_llm = llm.with_structured_output(schema_class)

        result = await structured_llm.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])

        if result is None:
            logger.warning(f"[invoke_structured_llm] LLMì´ None ë°˜í™˜ (schema={schema_class.__name__})")
            return fallback_value

        return result

    except Exception as e:
        logger.error(f"[invoke_structured_llm] Structured LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return fallback_value


# -----------------------------------------------------------------------------
# 3. ì˜¨ë³´ë”© ê´€ë ¨ ê³µí†µ ë¡œì§
# -----------------------------------------------------------------------------

async def save_onboarding_conversation(
    db,
    user_id: str,
    user_message: str,
    ai_message: str,
    max_history: int = 6
) -> None:
    """
    ì˜¨ë³´ë”© ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ (ìµœê·¼ Nê°œë§Œ ìœ ì§€)

    Args:
        db: Database ì¸ìŠ¤í„´ìŠ¤
        user_id: ì‚¬ìš©ì ID
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        ai_message: AI ì‘ë‹µ ë©”ì‹œì§€
        max_history: ìµœëŒ€ ìœ ì§€ í„´ ìˆ˜ (ê¸°ë³¸ 6ê°œ = 3í„´)

    Usage:
        onboarding_agent_nodeì—ì„œ ëŒ€í™” ì§„í–‰ ì¤‘ íˆìŠ¤í† ë¦¬ ì €ì¥
    """
    conv_state = await db.get_conversation_state(user_id)
    recent_messages = []

    if conv_state and conv_state.get("temp_data"):
        recent_messages = conv_state["temp_data"].get("onboarding_messages", [])[-max_history:]

    recent_messages.append({"role": "user", "content": user_message})
    recent_messages.append({"role": "assistant", "content": ai_message})
    recent_messages = recent_messages[-max_history:]  # ìµœê·¼ Nê°œë§Œ ìœ ì§€

    await db.upsert_conversation_state(
        user_id,
        current_step="onboarding",
        temp_data={"onboarding_messages": recent_messages}
    )


async def update_onboarding_state(
    db,
    user_id: str,
    metadata,  # UserMetadata íƒ€ì…
    ai_response: str,
    user_message: Optional[str] = None
) -> None:
    """
    ì˜¨ë³´ë”© ë©”íƒ€ë°ì´í„° + ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬

    Args:
        db: Database ì¸ìŠ¤í„´ìŠ¤
        user_id: ì‚¬ìš©ì ID
        metadata: UserMetadata ê°ì²´
        ai_response: AI ì‘ë‹µ ë©”ì‹œì§€
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€ (ìˆìœ¼ë©´ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€)

    Usage:
        onboarding_agent_nodeì—ì„œ ë©”íƒ€ë°ì´í„° ì €ì¥ + íˆìŠ¤í† ë¦¬ ì €ì¥ì„ í•œ ë²ˆì—
    """
    from ..database import save_onboarding_metadata

    # ë©”íƒ€ë°ì´í„° ì €ì¥
    await save_onboarding_metadata(db, user_id, metadata)

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ (user_messageê°€ ìˆì„ ë•Œë§Œ)
    if user_message:
        await save_onboarding_conversation(db, user_id, user_message, ai_response)


# -----------------------------------------------------------------------------
# 4. 7ì¼ì°¨ ì²´í¬ ë° ì£¼ê°„ ìš”ì•½ ì œì•ˆ (í•µì‹¬ ì¤‘ë³µ ë¡œì§)
# -----------------------------------------------------------------------------

async def check_and_suggest_weekly_summary(
    db,
    user_id: str,
    user_context,  # UserContext íƒ€ì…
    current_attendance_count: int,
    ai_response: str,
    message: str,
    is_summary: bool = True,
    summary_type: str = 'daily'
) -> Tuple[str, bool]:
    """
    7ì¼ì°¨ ë‹¬ì„± ì‹œ ì£¼ê°„ ìš”ì•½ ì œì•ˆ ë¡œì§ (ì¤‘ë³µ ì œê±°ìš©)

    Args:
        db: Database ì¸ìŠ¤í„´ìŠ¤
        user_id: ì‚¬ìš©ì ID
        user_context: UserContext ê°ì²´
        current_attendance_count: í˜„ì¬ ì¶œì„ ì¼ìˆ˜
        ai_response: ê¸°ë³¸ AI ì‘ë‹µ (ìš”ì•½ í…ìŠ¤íŠ¸ ë“±)
        message: ì‚¬ìš©ì ë©”ì‹œì§€
        is_summary: ìš”ì•½ ì‘ë‹µ ì—¬ë¶€
        summary_type: ìš”ì•½ íƒ€ì… ('daily' ë“±)

    Returns:
        (ai_response_with_suggestion, should_suggest_weekly)
        - ai_response_with_suggestion: ì£¼ê°„ ìš”ì•½ ì œì•ˆ í¬í•¨ ì‘ë‹µ
        - should_suggest_weekly: ì£¼ê°„ ìš”ì•½ ì œì•ˆ ì—¬ë¶€ (True/False)

    Usage:
        daily_agent_nodeì—ì„œ ìš”ì•½ ìƒì„±/ìˆ˜ì • í›„ 7ì¼ì°¨ ì²´í¬
    """
    from ..database import set_weekly_summary_flag

    current_daily_count = user_context.daily_record_count

    # 7ì¼ì°¨ ì²´í¬ (7, 14, 21ì¼ì°¨ ë“±)
    if current_attendance_count > 0 and current_attendance_count % 7 == 0 and current_daily_count >= 5:
        # ì¤‘ë³µ ë°©ì§€: ì´ë¯¸ ì£¼ê°„ìš”ì•½ í”Œë˜ê·¸ê°€ ìˆìœ¼ë©´ ì œì•ˆí•˜ì§€ ì•ŠìŒ
        conv_state = await db.get_conversation_state(user_id)
        temp_data = conv_state.get("temp_data", {}) if conv_state else {}
        weekly_summary_ready = temp_data.get("weekly_summary_ready", False)

        if not weekly_summary_ready:
            logger.info(f"[check_weekly_summary] ğŸ‰ 7ì¼ì°¨ ë‹¬ì„±! (attendance={current_attendance_count}, daily={current_daily_count})")

            # ì£¼ê°„ ìš”ì•½ ì œì•ˆ ë©”ì‹œì§€ ì¶”ê°€
            ai_response_with_suggestion = f"{ai_response}\n\nğŸ‰ 7ì¼ì°¨ ë‹¬ì„±! ì£¼ê°„ ìš”ì•½ë„ ë³´ì—¬ë“œë¦´ê¹Œìš”?"

            # ëŒ€í™” ì €ì¥
            await db.save_conversation_turn(
                user_id,
                message,
                ai_response_with_suggestion,
                is_summary=is_summary,
                summary_type=summary_type
            )

            # ì£¼ê°„ ìš”ì•½ í”Œë˜ê·¸ ì„¤ì •
            await set_weekly_summary_flag(db, user_id, current_attendance_count, user_context.daily_session_data)

            return ai_response_with_suggestion, True
        else:
            logger.info(f"[check_weekly_summary] 7ì¼ì°¨ì§€ë§Œ ì´ë¯¸ ì£¼ê°„ìš”ì•½ í”Œë˜ê·¸ ì¡´ì¬ â†’ ì œì•ˆ ìƒëµ")
            # í”Œë˜ê·¸ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì¼ë°˜ ìš”ì•½ìœ¼ë¡œ ì²˜ë¦¬ (ì œì•ˆ ì—†ì´)
            return ai_response, False

    # 7ì¼ì°¨ ì•„ë‹˜
    return ai_response, False


# -----------------------------------------------------------------------------
# 5. Command ì‘ë‹µ ìƒì„± í—¬í¼
# -----------------------------------------------------------------------------

def error_command(error_message: str = "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", goto: str = "__end__"):
    """
    ì—ëŸ¬ ì‘ë‹µ Command ìƒì„±

    Args:
        error_message: ì—ëŸ¬ ë©”ì‹œì§€
        goto: ì´ë™í•  ë…¸ë“œ (ê¸°ë³¸ê°’: "__end__")

    Returns:
        Command ê°ì²´

    Usage:
        ëª¨ë“  ë…¸ë“œì—ì„œ ì—ëŸ¬ ì²˜ë¦¬ ì‹œ í†µì¼ëœ ì‘ë‹µ
    """
    from langgraph.types import Command
    return Command(update={"ai_response": error_message}, goto=goto)


def success_command(ai_response: str, user_context=None, goto: str = "__end__"):
    """
    ì„±ê³µ ì‘ë‹µ Command ìƒì„± (user_context ì—…ë°ì´íŠ¸ í¬í•¨)

    Args:
        ai_response: AI ì‘ë‹µ ë©”ì‹œì§€
        user_context: UserContext ê°ì²´ (ìˆìœ¼ë©´ í•¨ê»˜ ì—…ë°ì´íŠ¸)
        goto: ì´ë™í•  ë…¸ë“œ (ê¸°ë³¸ê°’: "__end__")

    Returns:
        Command ê°ì²´

    Usage:
        ëª¨ë“  ë…¸ë“œì—ì„œ ì •ìƒ ì‘ë‹µ ì‹œ í†µì¼ëœ ì‘ë‹µ
    """
    from langgraph.types import Command

    updates = {"ai_response": ai_response}
    if user_context is not None:
        updates["user_context"] = user_context

    return Command(update=updates, goto=goto)


# -----------------------------------------------------------------------------
# 6. ì„¸ì…˜ ë°ì´í„° ê´€ë¦¬
# -----------------------------------------------------------------------------

def reset_session_data(user_context) -> None:
    """
    daily_session_dataë¥¼ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”

    Args:
        user_context: UserContext ê°ì²´

    Usage:
        ëŒ€í™” ê±°ì ˆ, ì¢…ë£Œ, ì¬ì‹œì‘ ì‹œ ì„¸ì…˜ ì´ˆê¸°í™”
    """
    user_context.daily_session_data = {}


# -----------------------------------------------------------------------------
# 7. ëŒ€í™” ì €ì¥ + ì¹´ìš´íŠ¸ ì¦ê°€ í†µí•©
# -----------------------------------------------------------------------------

async def save_and_increment(
    db,
    user_id: str,
    user_message: str,
    ai_response: str,
    user_context,  # UserContext íƒ€ì…
    is_summary: bool = False,
    summary_type: Optional[str] = None,
    should_increment: bool = True
) -> Tuple[int, Optional[int]]:
    """
    ëŒ€í™” ì €ì¥ + daily_record_count ì¦ê°€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬

    Args:
        db: Database ì¸ìŠ¤í„´ìŠ¤
        user_id: ì‚¬ìš©ì ID
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        ai_response: AI ì‘ë‹µ ë©”ì‹œì§€
        user_context: UserContext ê°ì²´
        is_summary: ìš”ì•½ ì‘ë‹µ ì—¬ë¶€
        summary_type: ìš”ì•½ íƒ€ì… ('daily' ë˜ëŠ” 'weekly')
        should_increment: ì¹´ìš´íŠ¸ ì¦ê°€ ì—¬ë¶€ (ìš”ì•½ ìƒì„± ì‹œì—ëŠ” False)

    Returns:
        (updated_daily_count, new_attendance)
        - updated_daily_count: ì—…ë°ì´íŠ¸ëœ daily_record_count
        - new_attendance: 5íšŒ ë‹¬ì„± ì‹œ ìƒˆë¡œìš´ ì¶œì„ ì¼ìˆ˜ (ì•„ë‹ˆë©´ None)

    Usage:
        daily_agent_nodeì—ì„œ ëŒ€í™” ì €ì¥ + ì¹´ìš´íŠ¸ ì¦ê°€ ë¡œì§ í†µí•©
    """
    from ..database import increment_counts_with_check

    # ëŒ€í™” ì €ì¥
    await db.save_conversation_turn(
        user_id,
        user_message,
        ai_response,
        is_summary=is_summary,
        summary_type=summary_type if is_summary else None
    )

    # ì¹´ìš´íŠ¸ ì¦ê°€ (í•„ìš” ì‹œ)
    if should_increment:
        updated_daily_count, new_attendance = await increment_counts_with_check(db, user_id)

        if new_attendance:
            logger.info(f"[save_and_increment] ğŸ‰ 5íšŒ ë‹¬ì„±! attendance_count ì¦ê°€: {new_attendance}ì¼ì°¨")
            user_context.attendance_count = new_attendance

        logger.info(f"[save_and_increment] daily_record_count ì—…ë°ì´íŠ¸: {updated_daily_count}íšŒ")
        return updated_daily_count, new_attendance
    else:
        # ì¹´ìš´íŠ¸ ì¦ê°€ ì•ˆ í•¨ (í˜„ì¬ ê°’ ìœ ì§€)
        logger.info(f"[save_and_increment] ìš”ì•½ ìƒì„± - daily_record_count ì¦ê°€ ì•ˆ í•¨")
        return user_context.daily_record_count, None


