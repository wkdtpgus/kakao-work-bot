"""ì£¼ê°„ í”¼ë“œë°± ì²˜ë¦¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (Weekly Agentìš©)"""
import logging
from typing import Tuple, Optional, Dict, Any
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class WeeklyFeedbackResponse:
    """ì£¼ê°„ í”¼ë“œë°± ì²˜ë¦¬ ê²°ê³¼"""
    ai_response: str
    is_summary: bool = False
    summary_type: Optional[str] = None
    should_clear_flag: bool = False  # ì •ì‹ ì£¼ê°„ìš”ì•½ ìƒì„± í›„ í”Œë˜ê·¸ ì •ë¦¬ í•„ìš” ì—¬ë¶€


# handle_official_weekly_feedback, handle_no_record_yet, handle_partial_weekly_feedback ì œê±°ë¨
# ì´ì œ weekly_v1 â†’ weekly_qna â†’ weekly_v2 í”Œë¡œìš°ë§Œ ì‚¬ìš©


async def handle_weekly_v1_request(
    db,
    user_id: str,
    metadata,
    llm
) -> WeeklyFeedbackResponse:
    """ì£¼ê°„ìš”ì•½ v1.0 + ì—­ì§ˆë¬¸ ìƒì„± (ì‚¬ìš©ì ìš”ì²­ ì‹œ)

    Args:
        db: Database ì¸ìŠ¤í„´ìŠ¤
        user_id: ì‚¬ìš©ì ID
        metadata: UserMetadata ê°ì²´
        llm: LLM ì¸ìŠ¤í„´ìŠ¤

    Returns:
        WeeklyFeedbackResponse: v1.0 + ì—­ì§ˆë¬¸
    """
    from ...database import prepare_weekly_feedback_data
    from .feedback_generator import generate_weekly_feedback
    from .follow_up_generator import generate_follow_up_questions

    logger.info(f"[WeeklyV1] ì£¼ê°„ìš”ì•½ v1.0 ìƒì„± ì‹œì‘")

    # v1.0 ìƒì„±
    user_data = {
        "name": metadata.name,
        "job_title": metadata.job_title,
        "career_goal": metadata.career_goal
    }

    input_data = await prepare_weekly_feedback_data(db, user_id, user_data=user_data)
    v1_output = await generate_weekly_feedback(input_data, llm)

    # ì—­ì§ˆë¬¸ ìƒì„±
    follow_up_output = await generate_follow_up_questions(v1_output.feedback_text, llm)

    # temp_dataì— ì €ì¥ (v2.0 ìƒì„± ì‹œ í•„ìš”)
    conv_state = await db.get_conversation_state(user_id)
    temp_data = conv_state.get("temp_data", {}) if conv_state else {}

    temp_data["weekly_qna_session"] = {
        "active": True,
        "v1_summary": v1_output.feedback_text,
        "follow_up_questions": follow_up_output.questions,
        "turn_count": 0,
        "max_turns": 5,
        "conversation_history": []
    }

    # current_step ìœ ì§€
    current_step = conv_state.get("current_step", "weekly_qna") if conv_state else "weekly_qna"
    await db.upsert_conversation_state(user_id, current_step=current_step, temp_data=temp_data)

    # ì‘ë‹µ í¬ë§·íŒ…
    response = f"{v1_output.feedback_text}\n\nğŸ’¬ ê¶ê¸ˆí•œ ì ì´ ìˆì–´ìš”:\n"
    for i, q in enumerate(follow_up_output.questions, 1):
        response += f"{i}. {q}\n"

    logger.info(f"[WeeklyV1] v1.0 + ì—­ì§ˆë¬¸ ì œê³µ ì™„ë£Œ")

    return WeeklyFeedbackResponse(
        ai_response=response,
        is_summary=True,
        summary_type='weekly_v1'
    )


async def handle_weekly_qna_response(
    db,
    user_id: str,
    message: str,
    llm
) -> WeeklyFeedbackResponse:
    """ì—­ì§ˆë¬¸ í‹°í‚¤íƒ€ì¹´ ì²˜ë¦¬ (ìµœëŒ€ 5íšŒ)

    Args:
        db: Database ì¸ìŠ¤í„´ìŠ¤
        user_id: ì‚¬ìš©ì ID
        message: ì‚¬ìš©ì ë©”ì‹œì§€
        llm: LLM ì¸ìŠ¤í„´ìŠ¤

    Returns:
        WeeklyFeedbackResponse: í‹°í‚¤íƒ€ì¹´ ì‘ë‹µ or v2.0
    """
    from langchain_core.messages import SystemMessage, HumanMessage

    # ì„¸ì…˜ ì¡°íšŒ
    conv_state = await db.get_conversation_state(user_id)
    temp_data = conv_state.get("temp_data", {}) if conv_state else {}
    session = temp_data.get("weekly_qna_session")

    if not session or not session.get("active"):
        return WeeklyFeedbackResponse(
            ai_response="ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆì–´ìš”. ë‹¤ì‹œ ì£¼ê°„ìš”ì•½ì„ ìš”ì²­í•´ì£¼ì„¸ìš”."
        )

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
    session["conversation_history"].append({"user": message})
    session["turn_count"] += 1

    # 5íšŒ ë‹¬ì„± â†’ v2.0 ìƒì„±
    if session["turn_count"] >= session["max_turns"]:
        return await generate_weekly_v2(db, user_id, session, llm)

    # ìì—°ìŠ¤ëŸ¬ìš´ í›„ì† ì§ˆë¬¸ ìƒì„±
    from ...prompt.weekly_summary_prompt import (
        WEEKLY_TIKITAKA_QUESTION_PROMPT,
        WEEKLY_TIKITAKA_FINAL_QUESTION_PROMPT
    )

    # 5ë²ˆì§¸ í„´(ë§ˆì§€ë§‰ ì§ˆë¬¸) â†’ ëŒ€í™” ë§ˆë¬´ë¦¬ + ì†Œê° ìš”ì²­
    is_final_turn = (session["turn_count"] == session["max_turns"])
    system_prompt = WEEKLY_TIKITAKA_FINAL_QUESTION_PROMPT if is_final_turn else WEEKLY_TIKITAKA_QUESTION_PROMPT

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ì‚¬ìš©ì ë‹µë³€: {message}")
    ]

    response = await llm.ainvoke(messages)
    follow_up = response.content

    session["conversation_history"][-1]["ai"] = follow_up

    # ì„¸ì…˜ ì—…ë°ì´íŠ¸
    temp_data["weekly_qna_session"] = session
    # current_step ìœ ì§€
    conv_state = await db.get_conversation_state(user_id)
    current_step = conv_state.get("current_step", "weekly_qna") if conv_state else "weekly_qna"
    await db.upsert_conversation_state(user_id, current_step=current_step, temp_data=temp_data)

    logger.info(f"[WeeklyQnA] í‹°í‚¤íƒ€ì¹´ ì§„í–‰ ì¤‘: {session['turn_count']}/{session['max_turns']}")

    return WeeklyFeedbackResponse(ai_response=follow_up)


async def generate_weekly_v2(
    db,
    user_id: str,
    session: dict,
    llm
) -> WeeklyFeedbackResponse:
    """ì£¼ê°„ìš”ì•½ v2.0 ìƒì„± (QnA ì™„ë£Œ í›„)

    Args:
        db: Database ì¸ìŠ¤í„´ìŠ¤
        user_id: ì‚¬ìš©ì ID
        session: QnA ì„¸ì…˜ ë°ì´í„°
        llm: LLM ì¸ìŠ¤í„´ìŠ¤

    Returns:
        WeeklyFeedbackResponse: v2.0
    """
    from langchain_core.messages import SystemMessage, HumanMessage
    from ...prompt.weekly_summary_prompt import WEEKLY_V2_GENERATION_PROMPT

    logger.info(f"[WeeklyV2] ì£¼ê°„ìš”ì•½ v2.0 ìƒì„± ì‹œì‘")

    # v1.0 + QnA íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…
    v1_summary = session["v1_summary"]
    qna_history = session["conversation_history"]

    qna_text = "\n\n".join([
        f"Q: {turn.get('ai', '')}\nA: {turn.get('user', '')}"
        for turn in qna_history
        if turn.get('ai') and turn.get('user')
    ])

    messages = [
        SystemMessage(content=WEEKLY_V2_GENERATION_PROMPT),
        HumanMessage(content=f"# v1.0 ìš”ì•½\n{v1_summary}\n\n# ì¶”ê°€ ëŒ€í™”\n{qna_text}")
    ]

    response = await llm.ainvoke(messages)
    v2_summary = response.content

    # v2.0 ì €ì¥
    await db.save_conversation_turn(
        user_id,
        user_message="ì£¼ê°„ìš”ì•½ v2.0 ìƒì„±",
        ai_message=v2_summary,
        is_summary=True,
        summary_type='weekly_v2'
    )

    # ì„¸ì…˜ ì¢…ë£Œ + weekly_completed_week ì„¤ì • (ì¤‘ë³µ ë°©ì§€)
    from ...config import get_kst_now

    session["active"] = False
    conv_state = await db.get_conversation_state(user_id)
    temp_data = conv_state.get("temp_data", {}) if conv_state else {}
    temp_data["weekly_qna_session"] = session

    # ì´ë²ˆ ì£¼ ì™„ë£Œ í‘œì‹œ (ISO ì£¼ì°¨ ë²ˆí˜¸ ì‚¬ìš©, í•œêµ­ ì‹œê°„ ê¸°ì¤€)
    now = get_kst_now()
    current_week = now.isocalendar()[1]  # ISO ì£¼ì°¨ (1-53)
    temp_data["weekly_completed_week"] = current_week

    # current_step ìœ ì§€
    current_step = conv_state.get("current_step", "weekly_completed") if conv_state else "weekly_completed"
    await db.upsert_conversation_state(user_id, current_step=current_step, temp_data=temp_data)

    logger.info(f"[WeeklyV2] v2.0 ìƒì„± ì™„ë£Œ, ì„¸ì…˜ ì¢…ë£Œ")

    return WeeklyFeedbackResponse(
        ai_response=f"{v2_summary}\n\nìˆ˜ê³ í•˜ì…¨ì–´ìš”! ë‹¤ìŒ ì£¼ì—ë„ ì—´ì‹¬íˆ ê¸°ë¡í•´ë´ìš”! ğŸ˜Š",
        is_summary=True,
        summary_type='weekly_v2'
    )


# process_weekly_feedback ì œê±°ë¨ - weekly_agent_nodeì—ì„œ ì„¸ì…˜ ê¸°ë°˜ ë¶„ê¸°ë¡œ ëŒ€ì²´
# ì´ì œ weekly_v1 â†’ weekly_qna â†’ weekly_v2 í”Œë¡œìš°ë§Œ ì‚¬ìš©
