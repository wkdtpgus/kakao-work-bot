"""ì¼ì¼ ìš”ì•½ ìƒì„± ì„œë¹„ìŠ¤ (ìˆœìˆ˜ LLM í˜¸ì¶œë§Œ)

DB ì ‘ê·¼ ë¡œì§ ì—†ìŒ - Repositoryì—ì„œ ì¤€ë¹„í•œ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ LLM í˜¸ì¶œë§Œ ìˆ˜í–‰
"""
from langchain_core.messages import SystemMessage, HumanMessage
from ...prompt.daily_summary_prompt import (
    DAILY_SUMMARY_SYSTEM_PROMPT,
    DAILY_SUMMARY_USER_PROMPT,
    DAILY_SUMMARY_EDIT_SYSTEM_PROMPT,
    DAILY_SUMMARY_EDIT_USER_PROMPT
)
from ...utils.schemas import DailySummaryInput, DailySummaryOutput
from langsmith import traceable
import logging

logger = logging.getLogger(__name__)


@traceable(name="generate_daily_summary")
async def generate_daily_summary(
    input_data: DailySummaryInput,
    llm
) -> DailySummaryOutput:
    """ì¼ì¼ ìš”ì•½ ìƒì„± ë˜ëŠ” ìˆ˜ì • (ìˆœìˆ˜ LLM í˜¸ì¶œ)

    Args:
        input_data: Repositoryì—ì„œ ì¤€ë¹„í•œ ì…ë ¥ ë°ì´í„° (DailySummaryInput)
        llm: LLM ì¸ìŠ¤í„´ìŠ¤

    Returns:
        DailySummaryOutput: LLMì´ ìƒì„±í•œ ìš”ì•½ ê²°ê³¼
    """
    try:
        # ğŸ” ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
        logger.info(f"[DailySummary] ğŸ” latest_summary ì¡´ì¬ ì—¬ë¶€: {input_data.latest_summary is not None}")
        logger.info(f"[DailySummary] ğŸ” latest_summary ê¸¸ì´: {len(input_data.latest_summary) if input_data.latest_summary else 0}")
        logger.info(f"[DailySummary] ğŸ” user_correction: {input_data.user_correction[:50] if input_data.user_correction else 'None'}")

        # ===== ìˆ˜ì • ëª¨ë“œ (latest_summary ì¡´ì¬) =====
        if input_data.latest_summary:
            logger.info("[DailySummary] âœ… ìˆ˜ì • ëª¨ë“œ - ìµœì‹  ìš”ì•½ ê¸°ë°˜ ìˆ˜ì •")

            # ìˆ˜ì • ì „ìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            system_prompt = DAILY_SUMMARY_EDIT_SYSTEM_PROMPT
            user_prompt = DAILY_SUMMARY_EDIT_USER_PROMPT.format(
                user_correction=input_data.user_correction or "",
                existing_summary=input_data.latest_summary
            )

        # ===== ìƒì„± ëª¨ë“œ (latest_summary ì—†ìŒ) =====
        else:
            logger.info("[DailySummary] ìƒì„± ëª¨ë“œ - ì „ì²´ ëŒ€í™” ê¸°ë°˜ ìš”ì•½")

            # ì‚¬ìš©ì ë©”íƒ€ë°ì´í„° í…ìŠ¤íŠ¸ êµ¬ì„±
            user_metadata_text = f"""
- ì´ë¦„: {input_data.user_metadata.name}
- ì§ë¬´: {input_data.user_metadata.job_title}
- í”„ë¡œì íŠ¸: {input_data.user_metadata.project_name}
- ì»¤ë¦¬ì–´ ëª©í‘œ: {input_data.user_metadata.career_goal}
"""

            # ìƒì„± ì „ìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            system_prompt = DAILY_SUMMARY_SYSTEM_PROMPT
            user_prompt = DAILY_SUMMARY_USER_PROMPT.format(
                user_metadata=user_metadata_text,
                conversation_turns=input_data.conversation_context
            )

        # LLM í˜¸ì¶œ
        summary_response = await llm.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])

        summary_text = summary_response.content

        mode = "ìˆ˜ì •" if input_data.latest_summary else "ìƒì„±"
        logger.info(
            f"[DailySummary] ìš”ì•½ {mode} ì™„ë£Œ "
            f"(attendance_count={input_data.attendance_count}ì¼ì°¨, "
            f"daily_record_count={input_data.daily_record_count}íšŒ)"
        )

        return DailySummaryOutput(
            summary_text=summary_text
        )

    except Exception as e:
        logger.error(f"[DailySummary] ìš”ì•½ ìƒì„±/ìˆ˜ì • ì‹¤íŒ¨: {e}")
        raise
