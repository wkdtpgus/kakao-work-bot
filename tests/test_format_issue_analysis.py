"""
Format Compliance ë¬¸ì œ ìƒì„¸ ë¶„ì„ (CoT í‰ê°€)
"""
import asyncio
import os
from pathlib import Path
from langchain_core.messages import SystemMessage, HumanMessage
from src.utils.models import get_chat_llm
from test_daily_prompt_quality import COT_SUMMARY_PROMPT, SUMMARY_TEST_CASES

# GCP ì¸ì¦ ì„¤ì •
project_root = Path(__file__).parent
credentials_path = project_root / "thetimecollabo-38646deba34a.json"
if credentials_path.exists():
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(credentials_path)

async def analyze_format_issue():
    """Format Compliance ë¬¸ì œê°€ ë°œìƒí•œ ì¼€ì´ìŠ¤ë¥¼ CoTë¡œ ìƒì„¸ ë¶„ì„"""
    from src.prompt.daily_summary_prompt import DAILY_SUMMARY_SYSTEM_PROMPT as SUM_PROMPT

    # ë¬¸ì œê°€ ë°œìƒí•œ ì¼€ì´ìŠ¤ (ë¶€ì • ë‚´ìš© í¬í•¨ - ì ìˆ˜ 3.8)
    test_case = SUMMARY_TEST_CASES[1]

    llm = get_chat_llm()

    # ìš”ì•½ ìƒì„±
    user_prompt = f"""
# USER_INFO
{test_case["user_metadata"]}

# CONVERSATION
{test_case["conversation"]}
"""

    response = await llm.ainvoke([
        SystemMessage(content=SUM_PROMPT),
        HumanMessage(content=user_prompt)
    ])

    summary = response.content

    print("="*70)
    print("ğŸ“ ìƒì„±ëœ ìš”ì•½:")
    print("="*70)
    print(summary)
    print(f"\nê¸€ì ìˆ˜: {len(summary)}")

    # CoT í‰ê°€
    eval_prompt = COT_SUMMARY_PROMPT.format(
        conversation=test_case["conversation"],
        summary=summary,
        expected_quality=test_case["expected_quality"]
    )

    eval_response = await llm.ainvoke([HumanMessage(content=eval_prompt)])

    import json
    try:
        cot = json.loads(eval_response.content.replace("```json", "").replace("```", "").strip())
    except:
        print("\nâš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨")
        print(eval_response.content)
        return

    print("\n" + "="*70)
    print("ğŸ§  Chain-of-Thought ë¶„ì„ ê²°ê³¼")
    print("="*70)

    if 'step1_analysis' in cot:
        print("\n[Step 1] ëŒ€í™” ë¶„ì„:")
        analysis = cot['step1_analysis']
        print(f"  ì™„ë£Œí•œ ì‘ì—…: {analysis.get('completed_tasks', 'N/A')}")
        print(f"  ë¶€ì •í•œ ì‘ì—…: {analysis.get('denied_tasks', 'N/A')}")
        print(f"  í•µì‹¬ ë””í…Œì¼: {analysis.get('key_details', 'N/A')}")

    if 'step2_reasoning' in cot:
        print("\n[Step 2] ì„¸ë¶€ í‰ê°€:")
        for criterion, data in cot['step2_reasoning'].items():
            print(f"\n  {criterion}: {data.get('score', 'N/A')}/5")
            print(f"  â†’ {data.get('reasoning', 'N/A')}")

    if 'step3_final' in cot:
        final = cot['step3_final']
        print("\n[Step 3] ìµœì¢… íŒë‹¨:")
        print(f"  ì¢…í•© ì ìˆ˜: {final.get('overall_score', 'N/A')}/5")
        print(f"  ê°•ì : {', '.join(final.get('strengths', []))}")
        print(f"  ì•½ì : {', '.join(final.get('weaknesses', []))}")
        print(f"\n  ğŸ’¡ ê°œì„  ì œì•ˆ:")
        print(f"  {final.get('actionable_feedback', 'N/A')}")

if __name__ == "__main__":
    asyncio.run(analyze_format_issue())
